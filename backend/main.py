from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from conversation import get_next_question, update_state, questions
from openai_client import get_openai_decision
from rules_excel import load_excel_rules
from logging_handler import log_interaction, generate_report
import uuid

# === App-Setup ===
app = FastAPI()
RULES = load_excel_rules()
SESSIONS = {}

# === CORS fÃ¼r Frontend erlauben ===
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === Fortschritt berechnen ===
def calculate_progress(state: dict) -> int:
    """Berechnet Fortschritt in Prozent anhand der beantworteten Fragen."""
    total_questions = len(questions)
    answered = len([key for key in state.keys() if state[key]])
    if total_questions == 0:
        return 0
    progress = int((answered / total_questions) * 100)
    return min(progress, 100)


# === Chat-Route ===
@app.post("/chat")
async def chat(request: Request):
    data = await request.json()
    message = data.get("message", "").strip()
    user_id = data.get("user_id", str(uuid.uuid4()))

    # Lade Session-Zustand oder erzeuge neuen
    state = SESSIONS.get(user_id, {})

    # === Sicherstellen, dass state ein dict ist ===
    if not isinstance(state, dict):
        state = {}

    # === ğŸŸ¢ Update State (RÃ¼ckgabe kann dict mit next_question sein) ===
    update_result = update_state(state, message)

    # ğŸŸ¢ Sicherstellen, dass state richtig aktualisiert wird
    state = update_result.get("state", update_result)
    SESSIONS[user_id] = state

    # ğŸŸ¢ Falls update_state bereits eine nÃ¤chste Frage mitliefert:
    if "next_question" in update_result:
        response_text = update_result["next_question"]
        options = update_result.get("options", [])
        progress = calculate_progress(state)

        return {
            "response": response_text,
            "options": options,
            "progress": progress
        }

    # === NÃ¤chste Frage bestimmen (falls update_state keine mitgegeben hat) ===
    next_q = get_next_question(state)

    if next_q:
        response_text = next_q["text"]
        options = next_q.get("options", [])
        progress = calculate_progress(state)

        return {
            "response": response_text,
            "options": options,
            "progress": progress
        }

    # === Wenn alle Fragen beantwortet sind â†’ GPT Entscheidung ===
    try:
        decision_data = get_openai_decision(state, RULES)

        # ğŸ”¹ Logging der Interaktion
        log_interaction(
            user_id=user_id,
            abschlussziel=state.get("abschlussziel", "Unbekannt"),
            studiengang=state.get("studiengang", "Unbekannt"),
            nutzerkategorie=(
                "master_intern" if state.get("hsbi_bachelor", "").lower() == "ja"
                else "master_extern" if state.get("abschlussziel", "").lower() == "master"
                else "bachelorbewerber"
            ),
            entscheidung=decision_data.get("decision", "Unklar")
        )

        return {
            "response": decision_data["formatted_response"],
            "decision": decision_data.get("decision", "Unklar"),
            "options": [],
            "progress": 100
        }
    except Exception as e:
        return {
            "response": f"âŒ Fehler bei der Entscheidungsanalyse: {e}",
            "options": [],
            "progress": 100
        }


# === Startseite-Test ===
@app.get("/")
def root():
    return {"message": "HSBI Chatbot Backend lÃ¤uft âœ…"}


@app.get("/report")
def get_report(days: int = 30):
    """
    Gibt eine Zusammenfassung der Chatbot-Nutzung im gewÃ¤hlten Zeitraum zurÃ¼ck.
    Beispiel: /report?days=7
    """
    from logging_handler import generate_report
    report = generate_report(days)
    return report
